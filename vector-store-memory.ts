import { Document } from '@langchain/core/documents';
import {
  BaseMessagePromptTemplateLike,
  ChatPromptTemplate,
} from '@langchain/core/prompts';
import { InputValues } from '@langchain/core/utils/types';
import { ChatOpenAI, OpenAIEmbeddings } from '@langchain/openai';
import csvParser from 'csv-parser';
import * as fs from 'fs';
import { MemoryVectorStore } from 'langchain/vectorstores/memory';
import { inspect } from 'util';

async function main() {
  // âœ… Embedding ëª¨ë¸ ìƒì„±
  const embeddings = new OpenAIEmbeddings();
  const vectorStore = new MemoryVectorStore(embeddings);

  // âœ… LLM (GPT) ëª¨ë¸ ì„¤ì •
  const llm = new ChatOpenAI({
    model: 'gpt-4o-mini',
    temperature: 0,
  });

  /**
   * ì‚¬ìš©ìë³„ ë°ì´í„°ë¥¼ Embedding í›„ MemoryVectorStoreì— ì €ì¥
   */
  async function storeUserData() {
    let documents: Document[] = [];
    [
      {
        channels: [
          {
            id: 101,
            name: 'í”„ë¡œì íŠ¸ íšŒì˜',
            created_at: '2024-02-01T10:00:00Z',
            members: [
              { user_id: 1, joined_at: '2024-02-01T10:05:00Z' },
              { user_id: 2, joined_at: '2024-02-01T10:10:00Z' },
            ],
            messages: [
              {
                id: 1001,
                user_id: 1,
                text: 'ë‹¤ìŒ í”„ë¡œì íŠ¸ ì¼ì • ë…¼ì˜í•©ì‹œë‹¤.',
                timestamp: '2024-02-01T11:00:00Z',
              },
              {
                id: 1002,
                user_id: 2,
                text: 'ì¢‹ì•„ìš”, ë‹¤ìŒì£¼ ìˆ˜ìš”ì¼ ì–´ë– ì‹ ê°€ìš”?',
                timestamp: '2024-02-01T11:05:00Z',
              },
              {
                id: 1002,
                user_id: 1,
                text: 'ì¢‹ì•„ìš”.',
                timestamp: '2024-02-01T11:05:00Z',
              },
            ],
            notes: [
              {
                id: 2001,
                user_id: 1,
                title: 'í”„ë¡œì íŠ¸ ê°œìš”',
                content: 'ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ë°˜ ì±—ë´‡ ê°œë°œì…ë‹ˆë‹¤.',
                timestamp: '2024-02-01T12:00:00Z',
              },
            ],
            tasks: [
              {
                id: 3001,
                user_id: 1,
                description: 'í”„ë¡œì íŠ¸ ê¸°íšì„œ ì‘ì„±',
                status: 'ì§„í–‰ ì¤‘',
                due_date: '2024-02-05',
              },
              {
                id: 3002,
                user_id: 2,
                description: 'UI ë””ìì¸ ì‘ì—…',
                status: 'ì™„ë£Œ',
                due_date: '2024-02-03',
              },
            ],
          },
        ],
        users: [
          {
            id: 1,
            name: 'ì§±êµ¬',
            email: 'zzanggu@example.com',
            created_at: '2024-01-01T09:00:00Z',
          },
          {
            id: 2,
            name: 'ì§±ì•„',
            email: 'zzanga@example.com',
            created_at: '2024-01-02T09:00:00Z',
          },
        ],
      },
    ].map((data) => {
      const doc = new Document({
        pageContent: JSON.stringify(data), // CSVì˜ text í•„ë“œ ì €ì¥
        metadata: {
          ...data,
          timestamp: 'timestamp', // íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
        },
      });
      documents.push(doc);
    });

    await vectorStore.addDocuments(documents);
    console.log(`âœ… MemoryVectorStoreì— ì €ì¥ ì™„ë£Œ`);
  }

  /**
   * ğŸ“Œ RAG ê¸°ë°˜ìœ¼ë¡œ AI ë‹µë³€ ìƒì„±
   */
  async function generateRAGResponse(query: string) {
    console.log(`ğŸ§ ì‚¬ìš©ìì˜ ì§ˆë¬¸: ${query}`);

    // ğŸ” ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    const filter = (doc: Document) => true;
    const relevantDocs = await vectorStore.similaritySearch(query, 3, filter);

    // ğŸ“ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const context = relevantDocs.map((doc) => doc.pageContent).join('\n');

    const promptTemplate: (
      | ChatPromptTemplate<InputValues, string>
      | BaseMessagePromptTemplateLike
    )[] = [
      [
        'system',
        'ë„ˆëŠ” ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ëŒ€ë‹µí•´ì•¼ í•´.',
      ],
      ['system', `ì°¸ê³ í•  ë‚´ìš©:\n${context.replace(/({|})/g, '$&$&')}`],
      ['human', '{input}'],
    ];

    console.log('ğŸ’¬ ì»¨í…ìŠ¤íŠ¸:', inspect(context, { depth: 10 }));

    const prompt = ChatPromptTemplate.fromMessages(promptTemplate);

    const chain = prompt.pipe(llm);
    const invokeParams = {
      input: query,
    };
    console.log('invokeParams', invokeParams);
    // ğŸ’¬ LLMì— ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±
    const response = await chain
      .invoke(invokeParams)
      .then((res) => res.content);

    console.log(`ğŸ¤– AI ì‘ë‹µ: ${response}`);
  }

  await storeUserData();
  await generateRAGResponse('í”„ë¡œì íŠ¸ ê¸°íšì„œ ì‘ì„± ì§„í–‰ì´ ì˜ ë˜ê³ ìˆë‚˜?');
}

main();
