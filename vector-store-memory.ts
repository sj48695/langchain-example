import {
  BaseMessagePromptTemplateLike,
  ChatPromptTemplate,
} from "@langchain/core/prompts";
import { InputValues } from "@langchain/core/utils/types";
import { Document } from "@langchain/core/documents";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import csvParser from "csv-parser";
import * as fs from "fs";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

async function main() {
  // âœ… Embedding ëª¨ë¸ ìƒì„±
  const embeddings = new OpenAIEmbeddings();
  const vectorStore = new MemoryVectorStore(embeddings);

  // âœ… LLM (GPT) ëª¨ë¸ ì„¤ì •
  const llm = new ChatOpenAI({
    // temperature: 0.7, // ì°½ì˜ì ì´ì§€ë§Œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜
    // modelName: "gpt-4", // GPT-4 ì‚¬ìš© ê°€ëŠ¥
    model: "gpt-4o-mini",
    temperature: 0,
  });

  /**
   * CSV íŒŒì¼ì„ ì½ê³  ë°ì´í„°ë¥¼ ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
   */
  async function readCSV(
    userId: string,
    filePath: string
  ): Promise<Document[]> {
    return new Promise((resolve, reject) => {
      const results: Document[] = [];
      fs.createReadStream(`./docs/${filePath}`)
        .pipe(csvParser())
        .on("data", (data) => {
          const doc = new Document({
            pageContent: data.text, // CSVì˜ text í•„ë“œ ì €ì¥
            metadata: {
              userId, // ì‚¬ìš©ì ID ì €ì¥
              timestamp: data.timestamp, // íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
            },
          });
          results.push(doc);
        })
        .on("end", () => resolve(results))
        .on("error", (error) => reject(error));
    });
  }

  /**
   * ì‚¬ìš©ìë³„ ë°ì´í„°ë¥¼ Embedding í›„ MemoryVectorStoreì— ì €ì¥
   */
  // async function storeUserData(userId: string, filePath: string) {
  //   const documents = await readCSV(userId, filePath);

  //   await vectorStore.addDocuments(documents);
  //   console.log(`âœ… ${userId}ì˜ ë°ì´í„° MemoryVectorStoreì— ì €ì¥ ì™„ë£Œ`);
  // }

  async function storeUserData() {
    // const documents = await readCSV(userId, filePath);
    let documents: Document[] = [];
    [
      { name: "ì§±êµ¬", age: 7 },
      { name: "í°ë‘¥ì´", age: 5 },
      { name: "ì§±ì•„", age: 3 },
    ].map((data) => {
      const doc = new Document({
        pageContent: JSON.stringify(data), // CSVì˜ text í•„ë“œ ì €ì¥
        metadata: {
          ...data,
          userId: data.name, // ì‚¬ìš©ì ID ì €ì¥
          timestamp: "timestamp", // íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
        },
      });
      documents.push(doc);
    });

    await vectorStore.addDocuments(documents);
    console.log(`âœ… MemoryVectorStoreì— ì €ì¥ ì™„ë£Œ`);
  }

  /**
   * ì‚¬ìš©ìë³„ ë°ì´í„° ê²€ìƒ‰ (ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°)
   */
  async function searchUserData(userId: string, query: string) {
    const filter = (doc: Document) => doc.metadata.userId === userId;
    const results = await vectorStore.similaritySearch(query, 3, filter);

    console.log(`ğŸ” ${userId}ì˜ [query: ${query}] ê²€ìƒ‰ ê²°ê³¼:`, results);
  }

  /**
   * ğŸ“Œ RAG ê¸°ë°˜ìœ¼ë¡œ AI ë‹µë³€ ìƒì„±
   */
  async function generateRAGResponse(userId: string, query: string) {
    console.log(`ğŸ§ ì‚¬ìš©ìì˜ ì§ˆë¬¸: ${query}`);

    // ğŸ” ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    const filter = (doc: Document) => doc.metadata.userId === userId;
    const relevantDocs = await vectorStore.similaritySearch(query, 3, filter);

    // ğŸ“ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const context = relevantDocs.map((doc) => doc.pageContent).join("\n");
    // const context =
    //   relevantDocs.length > 0
    //     ? relevantDocs
    //         .map((doc) => JSON.parse(doc.pageContent))
    //         .map((doc) => `ì´ë¦„: ${doc.name}, ë‚˜ì´: ${doc.age}`)
    //         .join("\n")
    //     : "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";

    const promptTemplate: (
      | ChatPromptTemplate<InputValues, string>
      | BaseMessagePromptTemplateLike
    )[] = [
      [
        "system",
        "ë„ˆëŠ” ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ëŒ€ë‹µí•´ì•¼ í•´.",
      ],
      ["system", `ì°¸ê³ í•  ë‚´ìš©:\n${context.replace(/({|})/g, "$&$&")}`],
      ["human", "{input}"],
    ];

    console.log("ğŸ’¬ ì»¨í…ìŠ¤íŠ¸:", context);

    const prompt = ChatPromptTemplate.fromMessages(promptTemplate);

    const chain = prompt.pipe(llm);
    const invokeParams = {
      input: query,
    };
    console.log("invokeParams", invokeParams);
    // ğŸ’¬ LLMì— ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±
    const response = await chain
      .invoke(invokeParams)
      .then((res) => res.content);

    console.log(`ğŸ¤– AI ì‘ë‹µ: ${response}`);
  }

  // âœ… ê²€ìƒ‰ ì‹¤í–‰ ì˜ˆì œ
  async function searchExample() {
    // await searchUserData("A", "LangChain ê´€ë ¨ ì •ë³´ê°€ í•„ìš”í•´.");
    // await searchUserData("B", "GPT ëª¨ë¸ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?");
    await generateRAGResponse("ì§±êµ¬", "ë‚´ ì´ë¦„ì€?");
    await generateRAGResponse("ì§±ì•„", "ë‚´ ë‚˜ì´ëŠ”?");
    await generateRAGResponse("ì§±êµ¬", "ì§±êµ¬ ë‚˜ì´ëŠ”?");
    await generateRAGResponse("ì§±ì•„", "ì§±ì•„ ë‚˜ì´ëŠ”?");
  }

  // await storeUserData("A", "a_user_data.csv");
  // await storeUserData("B", "b_user_data.csv");
  await storeUserData();
  searchExample();
}

main();
